---
title: "Chapter 4: Modelling"
format: html
editor: visual
---

# Modelling

Our modelling layer has two goals: (i) assign every bet or raise a live probability that the actor is bluff‑heavy, and (ii) roll per‑player statistics into a single "Optimality" KPI that balances value betting, smart aggression, and controlled bluffing. We lean on the poker‑AI literature for both feature choices and mathematical footing: Billings' work on computer‑poker evaluation [@Billings2006], Chen & Ankenman's equity‑versus‑price calculus [@ChenAnkenman2006], Sire's tournament‑flow statistics [@Sire2007], Teófilo's abstraction heuristics [@Kuznetsov2024], Kang & Shelton's HMM opponent‑modelling insights [@Kuznetsov2024], and modern variance‑reduction techniques (AIVAT [@Burch2020]). The subsections below detail our implementation, show the equations, and justify defaults with citations.

We need two layers of insight:

-   A **Hidden Markov Model (HMM)** that tags each bet or raise with a live bluff probability, and\
-   An **Optimality score** that aggregates edge, volume, and discipline into one number.

These choices echo classic computer‑poker work (Billings; Chen & Ankenman) [@Billings2006; @ChenAnkenman2006] and later real‑time opponent‑modelling papers (Kang & Shelton) [@Kuznetsov2024].

##### Hidden Markov Model: "Is this bet a bluff?"

Poker hands arrive as an unlabelled time series of actions. We do not directly observe whether a wager is value or bluff, yet that latent intent drives strategy. A Hidden Markov Model fits this setting.

From the transform stage we carry four statistics:

| Symbol      | Meaning                     |
|:------------|:----------------------------|
| $E$         | equity proxy                |
| $O$         | price offered (`WagerOdds`) |
| $G = O - E$ | **Bluff Gap**               |
| $R$         | relative bet size           |

{: #tbl:transform-stats tbl-cap="Table 2.1: Four transform‑stage statistics."}

##### Two‑state Gaussian HMM

We model hidden states **V** (Value) and **B** (Bluff). Each emits $(G, R)$ with independent normals; parameters and the transition matrix are **learned via Expectation--Maximization**. This is the simplest model that captures the qualitative **switches** noted in real‑time opponent studies [@Kuznetsov2024]. Early experiments with 3--4 states overfit.

##### Gaussian emissions

`BluffGap` and `RelativeBetSize` are roughly bell‑shaped after truncating tails. A diagonal covariance keeps the parameter count low and stabilizes EM.

Posterior coding gives

$$
p_{\mathrm{bluff}} := P\!\bigl(S_t = B \mid G_t, R_t\bigr)
$$ {#eq-pbluff}

If a player has **fewer than three aggressive actions**, we skip the model and leave the bluff field `NA` to avoid small‑sample noise.

We also considered logistic regression; the absence of labelled bluffs makes it impractical here.

##### Optimality score: from micro‑metrics to one KPI

The Optimality index answers: *Who is actually playing well once volume and bluff discipline are considered?* Starting from Chen & Ankenman's edge idea---take a call/bet/raise only when $$
\overline{E} - \overline{O} > 0,
$$ with $$
\overline{E} = \text{mean equity}, \qquad \overline{O} = \text{mean price paid},
$$ we add two modifiers:

| Modifier                                             | Rationale                                                                                                                       | Scaling                                                                                                              |
|:----------------|:-------------------------------------|:----------------|
| $\nu = \dfrac{n_{\text{actions}}}{n_{\text{hands}}}$ | Profitable spots taken more often grow the bankroll faster; normalising by hands avoids favouring marathon sessions.            | $0 \le \nu \le 1$                                                                                                    |
| $B$ (bluff bonus/penalty)                            | A controlled share of +EV bluffs raises win rate; the same share with negative edge accelerates losses (Billings et al., 2006). | $B=\begin{cases}1+\mathrm{BluffRate}, & \text{if Edge}>0\\[2pt] 1-\mathrm{BluffRate}, & \text{if Edge}<0\end{cases}$ |

{: #tbl:opt-modifiers tbl-cap="Table 4.1: Modifiers and scaling for the Optimality index."}

The final score is

$$
\mathrm{Opt} = (\overline{E} - \overline{O}) \times \nu \times B
$$ {#eq-opt}

##### Variance notes: "Making live EV readings believable"

Per‑action equity is notoriously noisy---river cards alone can swing expectation by a **full** pot. Following variance‑reduction ideas (e.g., AIVAT) [@Burch2020], we focus on **EV** rather than raw equity and, per street, use conditional expectations given the exposed board. Lower variance stabilizes both the HMM training and the Optimality ranking, making small‑hand samples less prone to lucky heat‑runs.

##### Next steps in modelling

1.  Replace `approx_equity()` with Monte‑Carlo equity simulation to remove lookup bias and handle arbitrary textures.\
2.  Tune the volume and bluff multipliers via grid search or Bayesian optimisation against a hold‑out of live profit traces.\
3.  Add a **Hero‑only** bluff metric that conditions on Hero's hole cards and opponent ranges (no opponent hole‑card peeks).
